# -*- coding: utf-8 -*-
"""Feed Forward Network using class.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ELPeNNlYEHKZ3yLBDKiFTWXkjKubo30v
"""

import numpy as np

class FeedForwardNN:
    def __init__(self, lr=0.1):
        self.w1 = np.array([
            [0.2, 0.3],
            [0.4, 0.5],
            [0.6, 0.7]
        ])
        self.b1 = np.array([[0.5, 0.8]])

        self.w2 = np.array([[0.1],
                            [0.2]])
        self.b2 = np.array([[0.3]])

        self.lr = lr

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def sigmoid_derivative(self, x):
        return x * (1 - x)

    def forward(self, X):
        self.z1 = np.dot(X, self.w1) + self.b1
        self.a1 = self.sigmoid(self.z1)

        self.z2 = np.dot(self.a1, self.w2) + self.b2
        self.a2 = self.sigmoid(self.z2)
        return self.a2

    def backward(self, X, y):
        d_loss_da2 = self.a2 - y
        d_loss_dz2 = d_loss_da2 * self.sigmoid_derivative(self.a2)

        self.dw2 = np.dot(self.a1.T, d_loss_dz2)
        self.db2 = np.sum(d_loss_dz2, axis=0, keepdims=True)

        d_loss_da1 = np.dot(d_loss_dz2, self.w2.T)
        d_loss_dz1 = d_loss_da1 * self.sigmoid_derivative(self.a1)

        self.dw1 = np.dot(X.T, d_loss_dz1)
        self.db1 = np.sum(d_loss_dz1, axis=0, keepdims=True)

    def update(self):
        self.w1 -= self.lr * self.dw1
        self.b1 -= self.lr * self.db1
        self.w2 -= self.lr * self.dw2
        self.b2 -= self.lr * self.db2

    def train(self, X, y, epochs=1000):
        for epoch in range(epochs):
            self.forward(X)
            self.backward(X, y)
            self.update()
            if (epoch + 1) % 100 == 0:
                loss = np.mean((y - self.a2) ** 2)
                print(f"Epoch {epoch+1}, Loss: {loss}")


X = np.array([[5, 10, 15]])
y = np.array([[1]])

model = FeedForwardNN(lr=0.1)
model.train(X, y, epochs=1000)

print("Final Output:")
print(model.forward(X))

